{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9841bd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "from warnings import filterwarnings\n",
    "\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b4613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conectar_sqlserver() -> pyodbc.Connection:\n",
    "    \"\"\"\n",
    "    Cria conex√£o com SQL Server\n",
    "\n",
    "    :return: Conex√£o pyodbc\n",
    "    :rtype: pyodbc.Connection\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "    conn = pyodbc.connect(os.getenv(\"SQL_CONNECTION_STRING\"))\n",
    "    return conn\n",
    "\n",
    "\n",
    "conn = conectar_sqlserver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2355d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_dados_superior_ies(arquivo_csv: str, dtype=str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carrega e trata os dados do CSV de institui√ß√µes de ensino superior.\n",
    "\n",
    "    :param arquivo_csv: Caminho para o arquivo CSV\n",
    "    :type arquivo_csv: str\n",
    "    :param dtype: Tipo de dado para as colunas\n",
    "    :return: DataFrame com os dados tratados\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        arquivo_csv,\n",
    "        sep=\";\",\n",
    "        encoding=\"latin1\",\n",
    "        dtype=dtype,  # type: ignore\n",
    "        low_memory=False,\n",
    "    )\n",
    "\n",
    "    # Tratamento de valores faltantes e padroniza√ß√£o de colunas espec√≠ficas\n",
    "    categoria_desconhecido = \"Desconhecido\"\n",
    "\n",
    "    df[\"NU_CEP_IES\"] = df[\"NU_CEP_IES\"].fillna(0).astype(str).str.zfill(8)\n",
    "    df[\"SG_IES\"] = df[\"SG_IES\"].fillna(categoria_desconhecido).astype(str)\n",
    "    df[\"DS_NUMERO_ENDERECO_IES\"] = [\n",
    "        i if \"s/n\" not in i.lower() and \"sn\" not in i.lower() and i != \"-\" else \"0\"\n",
    "        for i in df[\"DS_NUMERO_ENDERECO_IES\"].fillna(\"0\").astype(str)\n",
    "    ]\n",
    "    df[\"DS_COMPLEMENTO_ENDERECO_IES\"] = [\n",
    "        i if \"s/n\" not in i.lower() and i != \"-\" else categoria_desconhecido\n",
    "        for i in df[\"DS_COMPLEMENTO_ENDERECO_IES\"]\n",
    "        .fillna(categoria_desconhecido)\n",
    "        .astype(str)\n",
    "    ]\n",
    "    df[\"TP_ORGANIZACAO_ACADEMICA\"] = df[\"TP_ORGANIZACAO_ACADEMICA\"].map(\n",
    "        {\n",
    "            \"1\": \"Universidade\",\n",
    "            \"2\": \"Centro Universit√°rio\",\n",
    "            \"3\": \"Faculdade\",\n",
    "            \"4\": \"Instituto Federal de Educa√ß√£o, Ci√™ncia e Tecnologia\",\n",
    "            \"5\": \"Centro Federal de Educa√ß√£o Tecnol√≥gica\",\n",
    "        }\n",
    "    )\n",
    "    if \"TP_REDE\" in df.columns:\n",
    "        df[\"TP_REDE\"] = df[\"TP_REDE\"].map({\"1\": \"P√∫blica\", \"2\": \"Privada\"}).astype(str)\n",
    "    df[\"TP_CATEGORIA_ADMINISTRATIVA\"] = df[\"TP_CATEGORIA_ADMINISTRATIVA\"].map(\n",
    "        {\n",
    "            \"1\": \"P√∫blica Federal\",\n",
    "            \"2\": \"P√∫blica Estadual\",\n",
    "            \"3\": \"P√∫blica Municipal\",\n",
    "            \"4\": \"Privada com fins lucrativos\",\n",
    "            \"5\": \"Privada sem fins lucrativos\",\n",
    "            \"6\": \"Privada - Particular em sentido estrito\",\n",
    "            \"7\": \"Especial\",\n",
    "            \"8\": \"Privada comunit√°ria\",\n",
    "            \"9\": \"Privada confessional\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a40bfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_dados_superior_curso(arquivo_csv: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carrega e trata os dados do CSV de cursos de ensino superior.\n",
    "\n",
    "    :param arquivo_csv: Caminho para o arquivo CSV\n",
    "    :type arquivo_csv: str\n",
    "    :return: DataFrame com os dados tratados\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        arquivo_csv,\n",
    "        sep=\";\",\n",
    "        encoding=\"latin1\",\n",
    "        dtype=str,\n",
    "        low_memory=False,\n",
    "    )\n",
    "\n",
    "    # Tratamento de valores faltantes e padroniza√ß√£o de colunas espec√≠ficas\n",
    "    categoria_desconhecido = \"Desconhecido\"\n",
    "\n",
    "    df[\"NO_REGIAO\"] = df[\"NO_REGIAO\"].fillna(categoria_desconhecido).astype(str)\n",
    "    df[\"CO_REGIAO\"] = df[\"CO_REGIAO\"].fillna(0).astype(int)\n",
    "    df[\"NO_UF\"] = df[\"NO_UF\"].fillna(categoria_desconhecido).astype(str)\n",
    "    df[\"SG_UF\"] = df[\"SG_UF\"].fillna(categoria_desconhecido).astype(str)\n",
    "    df[\"CO_UF\"] = df[\"CO_UF\"].fillna(0).astype(int)\n",
    "    df[\"NO_MUNICIPIO\"] = df[\"NO_MUNICIPIO\"].fillna(categoria_desconhecido).astype(str)\n",
    "    df[\"CO_MUNICIPIO\"] = df[\"CO_MUNICIPIO\"].fillna(0).astype(int)\n",
    "\n",
    "    df[\"IN_CAPITAL\"] = [\n",
    "        i if i != \".\" else \"0\" for i in df[\"IN_CAPITAL\"].fillna(\"0\").astype(str)\n",
    "    ]\n",
    "\n",
    "    df[\"TP_GRAU_ACADEMICO\"] = (\n",
    "        df[\"TP_GRAU_ACADEMICO\"].fillna(categoria_desconhecido).astype(str)\n",
    "    )\n",
    "\n",
    "    df[\"TP_GRAU_ACADEMICO\"] = df[\"TP_GRAU_ACADEMICO\"].replace(\n",
    "        {\n",
    "            \"1\": \"Bacharelado\",\n",
    "            \"2\": \"Licenciatura\",\n",
    "            \"3\": \"Tecnol√≥gico\",\n",
    "            \"4\": \"Bacharelado e Licenciatura\",\n",
    "            \"5\": \"N√£o aplic√°vel\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df[\"TP_DIMENSAO\"] = df[\"TP_DIMENSAO\"].map(\n",
    "        {\n",
    "            \"1\": \"Cursos presenciais ofertados no Brasil\",\n",
    "            \"2\": \"Cursos a dist√¢ncia ofertados no Brasil\",\n",
    "            \"3\": \"Cursos a dist√¢ncia com dimens√£o de dados somente a n√≠vel Brasil\",\n",
    "            \"4\": \"Cursos a dist√¢ncia ofertados por institui√ß√µes brasileiras no exterior\",\n",
    "        }\n",
    "    )\n",
    "    df[\"TP_ORGANIZACAO_ACADEMICA\"] = df[\"TP_ORGANIZACAO_ACADEMICA\"].map(\n",
    "        {\n",
    "            \"1\": \"Universidade\",\n",
    "            \"2\": \"Centro Universit√°rio\",\n",
    "            \"3\": \"Faculdade\",\n",
    "            \"4\": \"Instituto Federal de Educa√ß√£o, Ci√™ncia e Tecnologia\",\n",
    "            \"5\": \"Centro Federal de Educa√ß√£o Tecnol√≥gica\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df[\"TP_REDE\"] = df[\"TP_REDE\"].map({\"1\": \"P√∫blica\", \"2\": \"Privada\"}).astype(str)\n",
    "    df[\"TP_CATEGORIA_ADMINISTRATIVA\"] = df[\"TP_CATEGORIA_ADMINISTRATIVA\"].map(\n",
    "        {\n",
    "            \"1\": \"P√∫blica Federal\",\n",
    "            \"2\": \"P√∫blica Estadual\",\n",
    "            \"3\": \"P√∫blica Municipal\",\n",
    "            \"4\": \"Privada com fins lucrativos\",\n",
    "            \"5\": \"Privada sem fins lucrativos\",\n",
    "            \"6\": \"Privada - Particular em sentido estrito\",\n",
    "            \"7\": \"Especial\",\n",
    "            \"8\": \"Privada comunit√°ria\",\n",
    "            \"9\": \"Privada confessional\",\n",
    "        }\n",
    "    )\n",
    "    df[\"TP_MODALIDADE_ENSINO\"] = df[\"TP_MODALIDADE_ENSINO\"].map(\n",
    "        {\"1\": \"Presencial\", \"2\": \"Curso a dist√¢ncia\"}\n",
    "    )\n",
    "    df[\"TP_NIVEL_ACADEMICO\"] = df[\"TP_NIVEL_ACADEMICO\"].map(\n",
    "        {\"1\": \"Gradua√ß√£o\", \"2\": \"Sequencial de Forma√ß√£o Espec√≠fica\"}\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88305acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratar_chaves_estrangeiras(\n",
    "    foreign_keys: dict, df_filtrado: pd.DataFrame, cursor: pyodbc.Cursor, esquema: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Verifica e mapeia chaves estrangeiras no DataFrame antes da inser√ß√£o.\n",
    "\n",
    "    :param foreign_keys: Dicion√°rio de chaves estrangeiras\n",
    "    :type foreign_keys: dict\n",
    "    :param df_filtrado: DataFrame a ser verificado\n",
    "    :type df_filtrado: pd.DataFrame\n",
    "    :param cursor: Cursor do banco de dados\n",
    "    :type cursor: pyodbc.Cursor\n",
    "    :param esquema: Esquema do banco de dados\n",
    "    :type esquema: str\n",
    "    :return: None\n",
    "    :rtype: None\n",
    "    \"\"\"\n",
    "    print(\"üîç Verificando e mapeando chaves estrangeiras...\")\n",
    "\n",
    "    for fk_coluna, (\n",
    "        ref_tabela,\n",
    "        ref_coluna,\n",
    "        ref_coluna_exibicao,\n",
    "    ) in foreign_keys.items():\n",
    "\n",
    "        if ref_coluna_exibicao not in df_filtrado.columns:\n",
    "            raise ValueError(\n",
    "                f\"‚ùå Erro: coluna '{ref_coluna_exibicao}' n√£o existe no DataFrame!\"\n",
    "            )\n",
    "\n",
    "        # Buscar valores v√°lidos\n",
    "        query = f\"\"\"\n",
    "            SELECT DISTINCT {ref_coluna}, {ref_coluna_exibicao}\n",
    "            FROM {esquema}.{ref_tabela}\n",
    "            WHERE {ref_coluna_exibicao} IS NOT NULL\n",
    "        \"\"\"\n",
    "        cursor.execute(query)\n",
    "        valores_validos = cursor.fetchall()\n",
    "\n",
    "        if not valores_validos:\n",
    "            raise ValueError(\n",
    "                f\"‚ùå A tabela {esquema}.{ref_tabela} n√£o possui valores v√°lidos para FK.\"\n",
    "            )\n",
    "\n",
    "        mapa_validos = {str(row[1]).strip().lower(): row[0] for row in valores_validos}\n",
    "\n",
    "        # Mapeamento\n",
    "        df_filtrado[fk_coluna] = (\n",
    "            df_filtrado[ref_coluna_exibicao]\n",
    "            .astype(str)\n",
    "            .str.strip()\n",
    "            .str.lower()\n",
    "            .map(mapa_validos)\n",
    "        )\n",
    "\n",
    "        # Verifica valores sem correspond√™ncia\n",
    "        ausentes = df_filtrado[df_filtrado[fk_coluna].isna()][\n",
    "            ref_coluna_exibicao\n",
    "        ].unique()\n",
    "        if len(ausentes) > 0:\n",
    "            print(\"\\n‚ö†Ô∏è Valores sem correspond√™ncia na FK:\")\n",
    "            for v in ausentes[:20]:\n",
    "                print(\"   -\", v)\n",
    "            raise ValueError(\n",
    "                f\"‚ùå Existem valores sem correspond√™ncia para a FK '{fk_coluna}'. Corrija antes de inserir.\"\n",
    "            )\n",
    "\n",
    "        df_filtrado[fk_coluna] = df_filtrado[fk_coluna].astype(int)\n",
    "        df_filtrado.drop(columns=[ref_coluna_exibicao], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd0cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inserir_lotes_dados(\n",
    "    conn: pyodbc.Connection,\n",
    "    cursor: pyodbc.Cursor,\n",
    "    tabela: str,\n",
    "    df_filtrado: pd.DataFrame,\n",
    "    sql_query: str,\n",
    "    n_lotes: int,\n",
    "    total_rows: int,\n",
    "    original_autocommit: bool,\n",
    "    esquema: str = \"inep\",\n",
    "    usar_identity_insert: bool = False,\n",
    "    tamanho_bloco: int = 1000,\n",
    "    max_tentativas: int = 3,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Insere dados em grandes lotes de dados na tabela com tentativas e tratamento de erros.\n",
    "\n",
    "    :param conn: Conex√£o com o banco de dados\n",
    "    :type conn: pyodbc.Connection\n",
    "    :param cursor: Cursor do banco de dados\n",
    "    :type cursor: pyodbc.Cursor\n",
    "    :param tabela: Nome da tabela de destino\n",
    "    :type tabela: str\n",
    "    :param df_filtrado: DataFrame com os dados a serem inseridos\n",
    "    :type df_filtrado: pd.DataFrame\n",
    "    :param sql: Comando SQL para inser√ß√£o\n",
    "    :type sql: str\n",
    "    :param n_batches: N√∫mero de lotes para inser√ß√£o\n",
    "    :type n_batches: int\n",
    "    :param total_rows: Total de linhas a serem inseridas\n",
    "    :type total_rows: int\n",
    "    :param original_autocommit: Estado original do autocommit da conex√£o\n",
    "    :type original_autocommit: bool\n",
    "    :param schema: Esquema do banco de dados\n",
    "    :type schema: str\n",
    "    :param usar_identity_insert: Habilitar IDENTITY_INSERT se necess√°rio\n",
    "    :type usar_identity_insert: bool\n",
    "    :param tamanho_bloco: N√∫mero de linhas por batch\n",
    "    :type tamanho_bloco: int\n",
    "    :param max_tentativas: N√∫mero m√°ximo de tentativas em caso de falha\n",
    "    :type max_tentativas: int\n",
    "    \"\"\"\n",
    "    print(f\"üöÄ Iniciando inser√ß√£o na tabela {esquema}.{tabela}\")\n",
    "    try:\n",
    "        conn.autocommit = True\n",
    "        bar = tqdm(\n",
    "            total=n_lotes,\n",
    "            desc=f\"Inserindo {tabela}\",\n",
    "            colour=\"blue\",\n",
    "            ncols=100,\n",
    "            unit=\"batch\",\n",
    "            unit_scale=True,\n",
    "        )\n",
    "        for batch_i in range(n_lotes):\n",
    "            inicio = batch_i * tamanho_bloco\n",
    "            fim = min(inicio + tamanho_bloco, total_rows)\n",
    "            batch_df = df_filtrado.iloc[inicio:fim]\n",
    "            data = [tuple(x) for x in batch_df.to_numpy()]\n",
    "\n",
    "            attempt = 0\n",
    "            while attempt < max_tentativas:\n",
    "                try:\n",
    "                    cursor.fast_executemany = True\n",
    "                    cursor.executemany(sql_query, data)\n",
    "                    bar.update(1)\n",
    "                    break\n",
    "\n",
    "                except pyodbc.OperationalError as e:\n",
    "                    attempt += 1\n",
    "                    tempo_espera = 2**attempt\n",
    "                    print(\n",
    "                        f\"‚ö†Ô∏è Falha no batch {batch_i+1}: {e}. Nova tentativa em {tempo_espera}s...\"\n",
    "                    )\n",
    "                    time.sleep(tempo_espera)\n",
    "                    cursor.close()\n",
    "                    cursor = conn.cursor()\n",
    "\n",
    "                except pyodbc.Error as ex:\n",
    "                    attempt += 1\n",
    "                    print(f\"SQL Server Error: {ex.args[0]} - {ex}\")\n",
    "                    conn.rollback()\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Erro irrevers√≠vel no batch {batch_i+1}: {e}\")\n",
    "                    raise\n",
    "\n",
    "    finally:\n",
    "        if usar_identity_insert:\n",
    "            try:\n",
    "                cursor.execute(f\"SET IDENTITY_INSERT {esquema}.{tabela} OFF;\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        conn.autocommit = original_autocommit\n",
    "        cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdef0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_dados(\n",
    "    conn: pyodbc.Connection,\n",
    "    tabela: str,\n",
    "    df_filtrado: pd.DataFrame,\n",
    "    chunk_size: int = 1000,\n",
    "    schema: str = \"inep\",\n",
    "    foreign_keys: dict = {},\n",
    "    usar_identity_insert: bool = False,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Insere o DataFrame em batches usando fast_executemany, com retry e autocommit tempor√°rio.\n",
    "    Inclui tratamento seguro de FOREIGN KEY antes da inser√ß√£o.\n",
    "\n",
    "    foreign_keys:\n",
    "        Exemplo:\n",
    "        {\n",
    "            'id_municipio': ('municipio', 'id_municipio', 'nome_municipio')\n",
    "        }\n",
    "\n",
    "    :param conn: Conex√£o com o banco de dados\n",
    "    :type conn: pyodbc.Connection\n",
    "    :param tabela: Nome da tabela de destino\n",
    "    :type tabela: str\n",
    "    :param df_filtrado: DataFrame a ser inserido\n",
    "    :type df_filtrado: pd.DataFrame\n",
    "    :param foreign_keys: Dicion√°rio de chaves estrangeiras para tratamento\n",
    "    :type foreign_keys: dict\n",
    "    :param chunk_size: N√∫mero de linhas por batch\n",
    "    :param chunk_size: Tamanho do lote para inser√ß√£o\n",
    "    :param schema: Nome do esquema do banco de dados\n",
    "    :type schema: str\n",
    "    :param usar_identity_insert: Habilitar IDENTITY_INSERT se necess√°rio\n",
    "    :type usar_identity_insert: bool\n",
    "    :return: None\n",
    "    :rtype: None\n",
    "    \"\"\"\n",
    "    original_autocommit = conn.autocommit\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # tratar chaves estrangeiras\n",
    "    if foreign_keys:\n",
    "        tratar_chaves_estrangeiras(foreign_keys, df_filtrado, cursor, schema)\n",
    "\n",
    "    # Habilitar IDENTITY_INSERT se necess√°rio\n",
    "    if usar_identity_insert:\n",
    "        try:\n",
    "            cursor.execute(f\"SET IDENTITY_INSERT {schema}.{tabela} ON;\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è N√£o foi poss√≠vel habilitar IDENTITY_INSERT: {e}\")\n",
    "\n",
    "    # Montar comando SQL de inser√ß√£o\n",
    "    colunas = \", \".join(df_filtrado.columns)\n",
    "    espa√ßos_reservados = \",\".join([\"?\"] * len(df_filtrado.columns))\n",
    "    sql_query = (\n",
    "        f\"INSERT INTO {schema}.{tabela} ({colunas}) VALUES ({espa√ßos_reservados})\"\n",
    "    )\n",
    "\n",
    "    total_linhas = len(df_filtrado)\n",
    "    if total_linhas == 0:\n",
    "        print(\"Nenhuma linha para inserir.\")\n",
    "        return\n",
    "\n",
    "    n_lotes = math.ceil(total_linhas / chunk_size)\n",
    "\n",
    "    # Inser√ß√£o dos lotes com tentativas\n",
    "    inserir_lotes_dados(\n",
    "        conn,\n",
    "        cursor,\n",
    "        tabela,\n",
    "        df_filtrado,\n",
    "        sql_query,\n",
    "        n_lotes,\n",
    "        total_linhas,\n",
    "        original_autocommit,\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Inser√ß√£o finalizada com sucesso na tabela {schema}.{tabela}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94341b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \"data/microdados_censo_da_educacao_superior_2020/dados/MICRODADOS_CADASTRO_IES_2020.CSV\",\n",
    "    \"data/microdados_censo_da_educacao_superior_2021/dados/MICRODADOS_CADASTRO_IES_2021.CSV\",\n",
    "    \"data/microdados_censo_da_educacao_superior_2022/dados/MICRODADOS_ED_SUP_IES_2022.CSV\",\n",
    "    \"data/microdados_censo_da_educacao_superior_2023/dados/MICRODADOS_ED_SUP_IES_2023.CSV\",\n",
    "    \"data/microdados_censo_da_educacao_superior_2024/dados/MICRODADOS_ED_SUP_IES_2024.CSV\",\n",
    "]\n",
    "df_ies_2024 = carregar_dados_superior_ies(\n",
    "    \"data/microdados_censo_da_educacao_superior_2024/dados/MICRODADOS_ED_SUP_IES_2024.CSV\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bdfc8c",
   "metadata": {},
   "source": [
    "# Tabela Regi√£o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52acc0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df_ies_2024[\n",
    "        [\n",
    "            \"CO_REGIAO_IES\",\n",
    "            \"NO_REGIAO_IES\",\n",
    "        ]\n",
    "    ]\n",
    "    .drop_duplicates(\"CO_REGIAO_IES\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df[\"CO_REGIAO_IES\"] = df[\"CO_REGIAO_IES\"].astype(int)\n",
    "df.sort_values(\"CO_REGIAO_IES\", inplace=True, ignore_index=True)\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        \"CO_REGIAO_IES\": \"id_regiao\",\n",
    "        \"NO_REGIAO_IES\": \"nome_regiao\",\n",
    "    }\n",
    ")\n",
    "insert_dados(conn, \"UF\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56980291",
   "metadata": {},
   "source": [
    "# Tabela Municipio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2823d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df_ies_2024[[\"CO_MUNICIPIO_IES\", \"NO_MUNICIPIO_IES\", \"CO_UF_IES\"]]\n",
    "    .drop_duplicates(\"CO_MUNICIPIO_IES\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df[\"CO_MUNICIPIO_IES\"] = df[\"CO_MUNICIPIO_IES\"].astype(int)\n",
    "df.sort_values(\"CO_MUNICIPIO_IES\", inplace=True, ignore_index=True)\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        \"CO_MUNICIPIO_IES\": \"id_municipio\",\n",
    "        \"NO_MUNICIPIO_IES\": \"nome_municipio\",\n",
    "        \"CO_UF_IES\": \"id_uf\",\n",
    "    }\n",
    ")\n",
    "insert_dados(conn, \"Municipio\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6fca5d",
   "metadata": {},
   "source": [
    "# Tabela Endere√ßo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3feab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ies_2024[\n",
    "    [\n",
    "        \"DS_ENDERECO_IES\",\n",
    "        \"DS_NUMERO_ENDERECO_IES\",\n",
    "        \"DS_COMPLEMENTO_ENDERECO_IES\",\n",
    "        \"NO_BAIRRO_IES\",\n",
    "        \"NU_CEP_IES\",\n",
    "        \"CO_MUNICIPIO_IES\",\n",
    "    ]\n",
    "].reset_index(drop=True)\n",
    "df[\"CO_MUNICIPIO_IES\"] = df[\"CO_MUNICIPIO_IES\"].astype(int)\n",
    "df[\"DS_ENDERECO_IES\"] = df[\"DS_ENDERECO_IES\"].str.title()\n",
    "df[\"DS_COMPLEMENTO_ENDERECO_IES\"] = df[\"DS_COMPLEMENTO_ENDERECO_IES\"].str.title()\n",
    "df[\"NO_BAIRRO_IES\"] = df[\"NO_BAIRRO_IES\"].str.title()\n",
    "df.sort_values(\"CO_MUNICIPIO_IES\", inplace=True, ignore_index=True)\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        \"DS_ENDERECO_IES\": \"endereco\",\n",
    "        \"DS_NUMERO_ENDERECO_IES\": \"numero_endereco\",\n",
    "        \"DS_COMPLEMENTO_ENDERECO_IES\": \"complemento\",\n",
    "        \"NO_BAIRRO_IES\": \"bairro\",\n",
    "        \"NU_CEP_IES\": \"cep\",\n",
    "        \"CO_MUNICIPIO_IES\": \"id_municipio\",\n",
    "    }\n",
    ")\n",
    "insert_dados(conn, \"Endereco\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d9f641",
   "metadata": {},
   "source": [
    "# Tabela Mantenedora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae4f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df_ies_2024[\n",
    "        [\n",
    "            \"CO_MANTENEDORA\",\n",
    "            \"NO_MANTENEDORA\",\n",
    "            \"TP_CATEGORIA_ADMINISTRATIVA\",\n",
    "            \"IN_COMUNITARIA\",\n",
    "            \"IN_CONFESSIONAL\",\n",
    "        ]\n",
    "    ]\n",
    "    .drop_duplicates(\"CO_MANTENEDORA\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df[\"CO_MANTENEDORA\"] = df[\"CO_MANTENEDORA\"].astype(int)\n",
    "df[\"IN_COMUNITARIA\"] = df[\"IN_COMUNITARIA\"].astype(int)\n",
    "df[\"IN_CONFESSIONAL\"] = df[\"IN_CONFESSIONAL\"].astype(int)\n",
    "df[\"NO_MANTENEDORA\"] = df[\"NO_MANTENEDORA\"].str.title()\n",
    "df.sort_values(\"CO_MANTENEDORA\", inplace=True, ignore_index=True)\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        \"CO_MANTENEDORA\": \"id_mantenedora\",\n",
    "        \"NO_MANTENEDORA\": \"nome_mantenedora\",\n",
    "        \"TP_CATEGORIA_ADMINISTRATIVA\": \"categoria_administrativa\",\n",
    "        \"IN_COMUNITARIA\": \"natureza_juridica_comunitaria\",\n",
    "        \"IN_CONFESSIONAL\": \"natureza_juridica_confessional\",\n",
    "    }\n",
    ")\n",
    "insert_dados(conn, \"Mantenedora\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea3ae28",
   "metadata": {},
   "source": [
    "# Tabela IES (Institui√ß√µes de Ensino Superior)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18dc896",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df_ies_2024[\n",
    "        [\n",
    "            \"CO_IES\",\n",
    "            \"NO_IES\",\n",
    "            \"SG_IES\",\n",
    "            \"TP_ORGANIZACAO_ACADEMICA\",\n",
    "            \"TP_REDE\",\n",
    "            \"IN_CAPITAL_IES\",\n",
    "            \"IN_ACESSO_PORTAL_CAPES\",\n",
    "            \"IN_ACESSO_OUTRAS_BASES\",\n",
    "            \"IN_ASSINA_OUTRA_BASE\",\n",
    "            \"IN_REPOSITORIO_INSTITUCIONAL\",\n",
    "            \"IN_BUSCA_INTEGRADA\",\n",
    "            \"IN_SERVICO_INTERNET\",\n",
    "            \"IN_PARTICIPA_REDE_SOCIAL\",\n",
    "            \"IN_CATALOGO_ONLINE\",\n",
    "            \"CO_MANTENEDORA\",\n",
    "            \"DS_ENDERECO_IES\",\n",
    "        ]\n",
    "    ]\n",
    "    .drop_duplicates(\"CO_IES\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df[\"CO_IES\"] = df[\"CO_IES\"].astype(int)\n",
    "df[\"IN_CAPITAL_IES\"] = df[\"IN_CAPITAL_IES\"].astype(int)\n",
    "df[\"CO_MANTENEDORA\"] = df[\"CO_MANTENEDORA\"].astype(int)\n",
    "df[\"NO_IES\"] = df[\"NO_IES\"].str.title()\n",
    "df.sort_values(\"CO_IES\", inplace=True, ignore_index=True)\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        \"CO_IES\": \"id_ies\",\n",
    "        \"NO_IES\": \"nome_ies\",\n",
    "        \"SG_IES\": \"sigla_ies\",\n",
    "        \"TP_ORGANIZACAO_ACADEMICA\": \"organizacao_academica\",\n",
    "        \"TP_REDE\": \"rede_ensino\",\n",
    "        \"IN_CAPITAL_IES\": \"sede_capital\",\n",
    "        \"IN_ACESSO_PORTAL_CAPES\": \"acesso_portal_capes\",\n",
    "        \"IN_ACESSO_OUTRAS_BASES\": \"acesso_outras_bases\",\n",
    "        \"IN_ASSINA_OUTRA_BASE\": \"assina_outra_base\",\n",
    "        \"IN_REPOSITORIO_INSTITUCIONAL\": \"repositorio_institucional\",\n",
    "        \"IN_BUSCA_INTEGRADA\": \"busca_integrada\",\n",
    "        \"IN_SERVICO_INTERNET\": \"servico_internet\",\n",
    "        \"IN_PARTICIPA_REDE_SOCIAL\": \"participa_rede_social\",\n",
    "        \"IN_CATALOGO_ONLINE\": \"catalogo_online\",\n",
    "        \"CO_MANTENEDORA\": \"id_mantenedora\",\n",
    "        \"DS_ENDERECO_IES\": \"endereco\",\n",
    "    }\n",
    ")\n",
    "insert_dados(\n",
    "    conn,\n",
    "    \"IES\",\n",
    "    df,\n",
    "    foreign_keys={\"id_endereco\": (\"Endereco\", \"id_endereco\", \"endereco\")},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694b8fa3",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de74f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_curso_2024 = carregar_dados_superior_curso(\n",
    "    \"data/microdados_censo_da_educacao_superior_2024/dados/MICRODADOS_CADASTRO_CURSOS_2024.CSV\"\n",
    ")\n",
    "df_curso_2024.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4892cab8",
   "metadata": {},
   "source": [
    "# Tabela Cine √Årea Geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1566ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df_curso_2024[\n",
    "        [\n",
    "            \"CO_CINE_AREA_GERAL\",\n",
    "            \"NO_CINE_AREA_GERAL\",\n",
    "        ]\n",
    "    ]\n",
    "    .drop_duplicates(\"CO_CINE_AREA_GERAL\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df[\"CO_CINE_AREA_GERAL\"] = df[\"CO_CINE_AREA_GERAL\"].astype(int)\n",
    "df.sort_values(\"CO_CINE_AREA_GERAL\", inplace=True, ignore_index=True)\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        \"CO_CINE_AREA_GERAL\": \"id_cine_area_geral\",\n",
    "        \"NO_CINE_AREA_GERAL\": \"nome_area_geral\",\n",
    "    }\n",
    ")\n",
    "insert_dados(conn, \"Cine_Area_Geral\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af4da3d",
   "metadata": {},
   "source": [
    "# Tabela Cine √Årea Espec√≠fica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4343f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df_curso_2024[\n",
    "        [\"CO_CINE_AREA_ESPECIFICA\", \"NO_CINE_AREA_ESPECIFICA\", \"CO_CINE_AREA_GERAL\"]\n",
    "    ]\n",
    "    .drop_duplicates(\"CO_CINE_AREA_ESPECIFICA\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df[\"CO_CINE_AREA_ESPECIFICA\"] = df[\"CO_CINE_AREA_ESPECIFICA\"].astype(int)\n",
    "df[\"CO_CINE_AREA_GERAL\"] = df[\"CO_CINE_AREA_GERAL\"].astype(int)\n",
    "df.sort_values(\"CO_CINE_AREA_ESPECIFICA\", inplace=True, ignore_index=True)\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        \"CO_CINE_AREA_ESPECIFICA\": \"id_cine_area_especifica\",\n",
    "        \"NO_CINE_AREA_ESPECIFICA\": \"nome_area_especifica\",\n",
    "        \"CO_CINE_AREA_GERAL\": \"id_cine_area_geral\",\n",
    "    }\n",
    ")\n",
    "insert_dados(conn, \"Cine_Area_Especifica\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a118442b",
   "metadata": {},
   "source": [
    "# Tabela Cine √Årea Detalhada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a16a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df_curso_2024[\n",
    "        [\"CO_CINE_AREA_DETALHADA\", \"NO_CINE_AREA_DETALHADA\", \"CO_CINE_AREA_ESPECIFICA\"]\n",
    "    ]\n",
    "    .drop_duplicates(\"CO_CINE_AREA_DETALHADA\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df[\"CO_CINE_AREA_DETALHADA\"] = df[\"CO_CINE_AREA_DETALHADA\"].astype(int)\n",
    "df[\"CO_CINE_AREA_ESPECIFICA\"] = df[\"CO_CINE_AREA_ESPECIFICA\"].astype(int)\n",
    "df.sort_values(\"CO_CINE_AREA_DETALHADA\", inplace=True, ignore_index=True)\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        \"CO_CINE_AREA_DETALHADA\": \"id_cine_area_detalhada\",\n",
    "        \"NO_CINE_AREA_DETALHADA\": \"nome_area_detalhada\",\n",
    "        \"CO_CINE_AREA_ESPECIFICA\": \"id_cine_area_especifica\",\n",
    "    }\n",
    ")\n",
    "insert_dados(conn, \"Cine_Area_Detalhada\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64572961",
   "metadata": {},
   "source": [
    "# Tabela Curso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61add597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df_curso_2024[\n",
    "        [\n",
    "            \"CO_CURSO\",\n",
    "            \"NO_CURSO\",\n",
    "            \"TP_GRAU_ACADEMICO\",\n",
    "            \"IN_GRATUITO\",\n",
    "            \"TP_MODALIDADE_ENSINO\",\n",
    "            \"TP_NIVEL_ACADEMICO\",\n",
    "            \"TP_DIMENSAO\",\n",
    "            \"CO_IES\",\n",
    "            \"CO_CINE_AREA_DETALHADA\",\n",
    "        ]\n",
    "    ]\n",
    "    .drop_duplicates(\"CO_CURSO\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df[\"CO_CURSO\"] = df[\"CO_CURSO\"].astype(int)\n",
    "df[\"CO_IES\"] = df[\"CO_IES\"].astype(int)\n",
    "df[\"CO_CINE_AREA_DETALHADA\"] = df[\"CO_CINE_AREA_DETALHADA\"].astype(int)\n",
    "df[\"IN_GRATUITO\"] = df[\"IN_GRATUITO\"].astype(int)\n",
    "df.sort_values(\"CO_CURSO\", inplace=True, ignore_index=True)\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        \"CO_CURSO\": \"id_curso\",\n",
    "        \"NO_CURSO\": \"nome_curso\",\n",
    "        \"TP_GRAU_ACADEMICO\": \"grau_academico\",\n",
    "        \"IN_GRATUITO\": \"gratuito\",\n",
    "        \"TP_MODALIDADE_ENSINO\": \"modalidade_ensino\",\n",
    "        \"TP_NIVEL_ACADEMICO\": \"nivel_academico\",\n",
    "        \"TP_DIMENSAO\": \"oferta\",\n",
    "        \"CO_IES\": \"id_ies\",\n",
    "        \"CO_CINE_AREA_DETALHADA\": \"id_cine_area_detalhada\",\n",
    "    }\n",
    ")\n",
    "insert_dados(conn, \"Curso\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d1520b",
   "metadata": {},
   "source": [
    "# Tabela IES por Ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f3043",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for dataset in datasets:\n",
    "    df_ies = carregar_dados_superior_ies(dataset)\n",
    "    df_ies = df_ies[df_ies[\"CO_IES\"].astype(int).isin(df_ies_2024)]\n",
    "    df = df_ies[\n",
    "        [\"QT_PERIODICO_ELETRONICO\", \"QT_LIVRO_ELETRONICO\", \"CO_IES\", \"NU_ANO_CENSO\"]\n",
    "    ]\n",
    "    df[\"CO_IES\"] = df[\"CO_IES\"].astype(int)\n",
    "    df[\"NU_ANO_CENSO\"] = df[\"NU_ANO_CENSO\"].astype(int)\n",
    "    df.sort_values([\"CO_IES\", \"NU_ANO_CENSO\"], inplace=True, ignore_index=True)\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"QT_PERIODICO_ELETRONICO\": \"qt_periodico_eletronico\",\n",
    "            \"QT_LIVRO_ELETRONICO\": \"qt_livro_eletronico\",\n",
    "            \"CO_IES\": \"id_ies\",\n",
    "            \"NU_ANO_CENSO\": \"id_ano\",\n",
    "        }\n",
    "    )\n",
    "    dfs.append(df)\n",
    "df_concat = pd.concat(dfs)\n",
    "df_concat.drop_duplicates(subset=[\"id_ies\", \"id_ano\"], inplace=True)\n",
    "insert_dados(conn, \"IES_Ano\", df_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c62a378",
   "metadata": {},
   "source": [
    "# Tabela Tecnico Administrativo por Ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad0a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for dataset in datasets:\n",
    "    df_ies = carregar_dados_superior_ies(dataset)\n",
    "    df_ies = df_ies[df_ies[\"CO_IES\"].astype(int).isin(df_ies_2024)]\n",
    "    df = df_ies[\n",
    "        [\n",
    "            \"QT_TEC_TOTAL\",\n",
    "            \"QT_TEC_FUNDAMENTAL_INCOMP_FEM\",\n",
    "            \"QT_TEC_FUNDAMENTAL_INCOMP_MASC\",\n",
    "            \"QT_TEC_FUNDAMENTAL_COMP_FEM\",\n",
    "            \"QT_TEC_FUNDAMENTAL_COMP_MASC\",\n",
    "            \"QT_TEC_MEDIO_FEM\",\n",
    "            \"QT_TEC_MEDIO_MASC\",\n",
    "            \"QT_TEC_SUPERIOR_FEM\",\n",
    "            \"QT_TEC_SUPERIOR_MASC\",\n",
    "            \"QT_TEC_ESPECIALIZACAO_FEM\",\n",
    "            \"QT_TEC_ESPECIALIZACAO_MASC\",\n",
    "            \"QT_TEC_MESTRADO_FEM\",\n",
    "            \"QT_TEC_MESTRADO_MASC\",\n",
    "            \"QT_TEC_DOUTORADO_FEM\",\n",
    "            \"QT_TEC_DOUTORADO_MASC\",\n",
    "            \"CO_IES\",\n",
    "            \"NU_ANO_CENSO\",\n",
    "        ]\n",
    "    ]\n",
    "    df[\"CO_IES\"] = df[\"CO_IES\"].astype(int)\n",
    "    df[\"NU_ANO_CENSO\"] = df[\"NU_ANO_CENSO\"].astype(int)\n",
    "    df.sort_values([\"CO_IES\", \"NU_ANO_CENSO\"], inplace=True, ignore_index=True)\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"QT_TEC_TOTAL\": \"qt_tec_total\",\n",
    "            \"QT_TEC_FUNDAMENTAL_INCOMP_FEM\": \"qt_tec_fundamental_incomp_fem\",\n",
    "            \"QT_TEC_FUNDAMENTAL_INCOMP_MASC\": \"qt_tec_fundamental_incomp_masc\",\n",
    "            \"QT_TEC_FUNDAMENTAL_COMP_FEM\": \"qt_tec_fundamental_comp_fem\",\n",
    "            \"QT_TEC_FUNDAMENTAL_COMP_MASC\": \"qt_tec_fundamental_comp_masc\",\n",
    "            \"QT_TEC_MEDIO_FEM\": \"qt_tec_medio_fem\",\n",
    "            \"QT_TEC_MEDIO_MASC\": \"qt_tec_medio_masc\",\n",
    "            \"QT_TEC_SUPERIOR_FEM\": \"qt_tec_superior_fem\",\n",
    "            \"QT_TEC_SUPERIOR_MASC\": \"qt_tec_superior_masc\",\n",
    "            \"QT_TEC_ESPECIALIZACAO_FEM\": \"qt_tec_especializacao_fem\",\n",
    "            \"QT_TEC_ESPECIALIZACAO_MASC\": \"qt_tec_especializacao_masc\",\n",
    "            \"QT_TEC_MESTRADO_FEM\": \"qt_tec_mestrado_fem\",\n",
    "            \"QT_TEC_MESTRADO_MASC\": \"qt_tec_mestrado_masc\",\n",
    "            \"QT_TEC_DOUTORADO_FEM\": \"qt_tec_doutorado_fem\",\n",
    "            \"QT_TEC_DOUTORADO_MASC\": \"qt_tec_doutorado_masc\",\n",
    "            \"CO_IES\": \"id_ies\",\n",
    "            \"NU_ANO_CENSO\": \"id_ano\",\n",
    "        }\n",
    "    )\n",
    "    dfs.append(df)\n",
    "df_concat = pd.concat(dfs)\n",
    "df_concat.drop_duplicates(subset=[\"id_ies\", \"id_ano\"], inplace=True)\n",
    "insert_dados(conn, \"Tecnico_Adm_Ano\", df_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d5b75b",
   "metadata": {},
   "source": [
    "# Tabela Docente por Ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086b7621",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for dataset in datasets:\n",
    "    df_ies = carregar_dados_superior_ies(dataset)\n",
    "    df_ies = df_ies[df_ies[\"CO_IES\"].astype(int).isin(df_ies_2024)]\n",
    "    df = df_ies[\n",
    "        [\n",
    "            \"QT_DOC_TOTAL\",\n",
    "            \"QT_DOC_EXE\",\n",
    "            \"QT_DOC_EX_FEMI\",\n",
    "            \"QT_DOC_EX_MASC\",\n",
    "            \"QT_DOC_EX_SEM_GRAD\",\n",
    "            \"QT_DOC_EX_GRAD\",\n",
    "            \"QT_DOC_EX_ESP\",\n",
    "            \"QT_DOC_EX_MEST\",\n",
    "            \"QT_DOC_EX_DOUT\",\n",
    "            \"QT_DOC_EX_INT\",\n",
    "            \"QT_DOC_EX_INT_DE\",\n",
    "            \"QT_DOC_EX_INT_SEM_DE\",\n",
    "            \"QT_DOC_EX_PARC\",\n",
    "            \"QT_DOC_EX_HOR\",\n",
    "            \"QT_DOC_EX_0_29\",\n",
    "            \"QT_DOC_EX_30_34\",\n",
    "            \"QT_DOC_EX_35_39\",\n",
    "            \"QT_DOC_EX_40_44\",\n",
    "            \"QT_DOC_EX_45_49\",\n",
    "            \"QT_DOC_EX_50_54\",\n",
    "            \"QT_DOC_EX_55_59\",\n",
    "            \"QT_DOC_EX_60_MAIS\",\n",
    "            \"QT_DOC_EX_BRANCA\",\n",
    "            \"QT_DOC_EX_PRETA\",\n",
    "            \"QT_DOC_EX_PARDA\",\n",
    "            \"QT_DOC_EX_AMARELA\",\n",
    "            \"QT_DOC_EX_INDIGENA\",\n",
    "            \"QT_DOC_EX_COR_ND\",\n",
    "            \"QT_DOC_EX_BRA\",\n",
    "            \"QT_DOC_EX_EST\",\n",
    "            \"QT_DOC_EX_COM_DEFICIENCIA\",\n",
    "            \"CO_IES\",\n",
    "            \"NU_ANO_CENSO\",\n",
    "        ]\n",
    "    ]\n",
    "    df[\"CO_IES\"] = df[\"CO_IES\"].astype(int)\n",
    "    df[\"NU_ANO_CENSO\"] = df[\"NU_ANO_CENSO\"].astype(int)\n",
    "    df.sort_values([\"CO_IES\", \"NU_ANO_CENSO\"], inplace=True, ignore_index=True)\n",
    "    colunas = df.columns.tolist()\n",
    "    colunas = [col.lower() for col in colunas if col not in [\"CO_IES\", \"NU_ANO_CENSO\"]]\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            col: col.lower()\n",
    "            for col in df.columns\n",
    "            if col not in [\"CO_IES\", \"NU_ANO_CENSO\"]\n",
    "        }\n",
    "    )\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"CO_IES\": \"id_ies\",\n",
    "            \"NU_ANO_CENSO\": \"id_ano\",\n",
    "        }\n",
    "    )\n",
    "    dfs.append(df)\n",
    "df_concat = pd.concat(dfs)\n",
    "df_concat.drop_duplicates(subset=[\"id_ies\", \"id_ano\"], inplace=True)\n",
    "insert_dados(conn, \"Docente_Ano\", df_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a9f8a",
   "metadata": {},
   "source": [
    "# Tabela Curso por Ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943de7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    df_curso = carregar_dados_superior_curso(dataset)\n",
    "    df_curso = df_curso[df_curso[\"CO_CURSO\"].astype(int).isin(df_curso_2024)]\n",
    "    df = df_curso[\n",
    "        [\n",
    "            \"QT_CURSO\",\n",
    "            \"QT_VG_TOTAL\",\n",
    "            \"QT_VG_TOTAL_DIURNO\",\n",
    "            \"QT_VG_TOTAL_NOTURNO\",\n",
    "            \"QT_VG_TOTAL_EAD\",\n",
    "            \"QT_VG_NOVA\",\n",
    "            \"QT_VG_PROC_SELETIVO\",\n",
    "            \"QT_VG_REMANESC\",\n",
    "            \"QT_VG_PROG_ESPECIAL\",\n",
    "            \"QT_INSCRITO_TOTAL\",\n",
    "            \"QT_INSCRITO_TOTAL_DIURNO\",\n",
    "            \"QT_INSCRITO_TOTAL_NOTURNO\",\n",
    "            \"QT_INSCRITO_TOTAL_EAD\",\n",
    "            \"QT_INSC_VG_NOVA\",\n",
    "            \"QT_INSC_PROC_SELETIVO\",\n",
    "            \"QT_INSC_VG_REMANESC\",\n",
    "            \"QT_INSC_VG_PROG_ESPECIAL\",\n",
    "            \"QT_ALUNO_DEFICIENTE\",\n",
    "            \"CO_CURSO\",\n",
    "            \"NU_ANO_CENSO\",\n",
    "        ]\n",
    "    ]\n",
    "    del df_curso\n",
    "    df[\"CO_CURSO\"] = df[\"CO_CURSO\"].astype(int)\n",
    "    df[\"NU_ANO_CENSO\"] = df[\"NU_ANO_CENSO\"].astype(int)\n",
    "    df.sort_values([\"CO_CURSO\", \"NU_ANO_CENSO\"], inplace=True, ignore_index=True)\n",
    "    colunas = df.columns.tolist()\n",
    "    colunas = [\n",
    "        col.lower() for col in colunas if col not in [\"CO_CURSO\", \"NU_ANO_CENSO\"]\n",
    "    ]\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            col: col.lower()\n",
    "            for col in df.columns\n",
    "            if col not in [\"CO_CURSO\", \"NU_ANO_CENSO\"]\n",
    "        }\n",
    "    )\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"CO_CURSO\": \"id_curso\",\n",
    "            \"NU_ANO_CENSO\": \"id_ano\",\n",
    "        }\n",
    "    )\n",
    "    df.drop_duplicates(subset=[\"id_curso\", \"id_ano\"], inplace=True)\n",
    "    insert_dados(conn, \"Curso_Ano\", df)\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150e111a",
   "metadata": {},
   "source": [
    "# Tabela Ingressante por Ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366941f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    df_curso = carregar_dados_superior_curso(dataset)\n",
    "    df_curso = df_curso[df_curso[\"CO_CURSO\"].astype(int).isin(df_curso_2024)]\n",
    "    df = df_curso[\n",
    "        [\n",
    "            \"QT_ING\",\n",
    "            \"QT_ING_FEM\",\n",
    "            \"QT_ING_MASC\",\n",
    "            \"QT_ING_DIURNO\",\n",
    "            \"QT_ING_NOTURNO\",\n",
    "            \"QT_ING_VG_NOVA\",\n",
    "            \"QT_ING_VESTIBULAR\",\n",
    "            \"QT_ING_ENEM\",\n",
    "            \"QT_ING_AVALIACAO_SERIADA\",\n",
    "            \"QT_ING_SELECAO_SIMPLIFICA\",\n",
    "            \"QT_ING_EGR\",\n",
    "            \"QT_ING_OUTRO_TIPO_SELECAO\",\n",
    "            \"QT_ING_PROC_SELETIVO\",\n",
    "            \"QT_ING_VG_REMANESC\",\n",
    "            \"QT_ING_VG_PROG_ESPECIAL\",\n",
    "            \"QT_ING_OUTRA_FORMA\",\n",
    "            \"QT_ING_0_17\",\n",
    "            \"QT_ING_18_24\",\n",
    "            \"QT_ING_25_29\",\n",
    "            \"QT_ING_30_34\",\n",
    "            \"QT_ING_35_39\",\n",
    "            \"QT_ING_40_49\",\n",
    "            \"QT_ING_50_59\",\n",
    "            \"QT_ING_60_MAIS\",\n",
    "            \"QT_ING_BRANCA\",\n",
    "            \"QT_ING_PRETA\",\n",
    "            \"QT_ING_PARDA\",\n",
    "            \"QT_ING_AMARELA\",\n",
    "            \"QT_ING_INDIGENA\",\n",
    "            \"QT_ING_CORND\",\n",
    "            \"QT_ING_NACBRAS\",\n",
    "            \"QT_ING_NACESTRANG\",\n",
    "            \"QT_ING_DEFICIENTE\",\n",
    "            \"CO_CURSO\",\n",
    "            \"NU_ANO_CENSO\",\n",
    "        ]\n",
    "    ]\n",
    "    del df_curso\n",
    "    df[\"CO_CURSO\"] = df[\"CO_CURSO\"].astype(int)\n",
    "    df[\"NU_ANO_CENSO\"] = df[\"NU_ANO_CENSO\"].astype(int)\n",
    "    df.sort_values([\"CO_CURSO\", \"NU_ANO_CENSO\"], inplace=True, ignore_index=True)\n",
    "    colunas = df.columns.tolist()\n",
    "    colunas = [\n",
    "        col.lower() for col in colunas if col not in [\"CO_CURSO\", \"NU_ANO_CENSO\"]\n",
    "    ]\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            col: col.lower()\n",
    "            for col in df.columns\n",
    "            if col not in [\"CO_CURSO\", \"NU_ANO_CENSO\"]\n",
    "        }\n",
    "    )\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"CO_CURSO\": \"id_curso\",\n",
    "            \"NU_ANO_CENSO\": \"id_ano\",\n",
    "        }\n",
    "    )\n",
    "    df.drop_duplicates(subset=[\"id_curso\", \"id_ano\"], inplace=True)\n",
    "    insert_dados(conn, \"Ingressante_Ano\", df)\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e635f",
   "metadata": {},
   "source": [
    "# Tabela Matricula por Ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb96633",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    df_curso = carregar_dados_superior_curso(dataset)\n",
    "    df_curso = df_curso[df_curso[\"CO_CURSO\"].astype(int).isin(df_curso_2024)]\n",
    "    df = df_curso[\n",
    "        [\n",
    "            \"QT_MAT\",\n",
    "            \"QT_MAT_FEM\",\n",
    "            \"QT_MAT_MASC\",\n",
    "            \"QT_MAT_DIURNO\",\n",
    "            \"QT_MAT_NOTURNO\",\n",
    "            \"QT_MAT_0_17\",\n",
    "            \"QT_MAT_18_24\",\n",
    "            \"QT_MAT_25_29\",\n",
    "            \"QT_MAT_30_34\",\n",
    "            \"QT_MAT_35_39\",\n",
    "            \"QT_MAT_40_49\",\n",
    "            \"QT_MAT_50_59\",\n",
    "            \"QT_MAT_60_MAIS\",\n",
    "            \"QT_MAT_BRANCA\",\n",
    "            \"QT_MAT_PRETA\",\n",
    "            \"QT_MAT_PARDA\",\n",
    "            \"QT_MAT_AMARELA\",\n",
    "            \"QT_MAT_INDIGENA\",\n",
    "            \"QT_MAT_CORND\",\n",
    "            \"CO_CURSO\",\n",
    "            \"NU_ANO_CENSO\",\n",
    "        ]\n",
    "    ]\n",
    "    del df_curso\n",
    "    df[\"CO_CURSO\"] = df[\"CO_CURSO\"].astype(int)\n",
    "    df[\"NU_ANO_CENSO\"] = df[\"NU_ANO_CENSO\"].astype(int)\n",
    "    df.sort_values([\"CO_CURSO\", \"NU_ANO_CENSO\"], inplace=True, ignore_index=True)\n",
    "    colunas = df.columns.tolist()\n",
    "    colunas = [\n",
    "        col.lower() for col in colunas if col not in [\"CO_CURSO\", \"NU_ANO_CENSO\"]\n",
    "    ]\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            col: col.lower()\n",
    "            for col in df.columns\n",
    "            if col not in [\"CO_CURSO\", \"NU_ANO_CENSO\"]\n",
    "        }\n",
    "    )\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"CO_CURSO\": \"id_curso\",\n",
    "            \"NU_ANO_CENSO\": \"id_ano\",\n",
    "        }\n",
    "    )\n",
    "    df.drop_duplicates(subset=[\"id_curso\", \"id_ano\"], inplace=True)\n",
    "    insert_dados(conn, \"Matricula_Ano\", df)\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0733730",
   "metadata": {},
   "source": [
    "# Tabela Concluinte por Ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b39363",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    df_curso = carregar_dados_superior_curso(dataset)\n",
    "    df_curso = df_curso[df_curso[\"CO_CURSO\"].astype(int).isin(df_curso_2024)]\n",
    "    df = df_curso[\n",
    "        [\n",
    "            \"QT_CONC\",\n",
    "            \"QT_CONC_FEM\",\n",
    "            \"QT_CONC_MASC\",\n",
    "            \"QT_CONC_DIURNO\",\n",
    "            \"QT_CONC_NOTURNO\",\n",
    "            \"QT_CONC_0_17\",\n",
    "            \"QT_CONC_18_24\",\n",
    "            \"QT_CONC_25_29\",\n",
    "            \"QT_CONC_30_34\",\n",
    "            \"QT_CONC_35_39\",\n",
    "            \"QT_CONC_40_49\",\n",
    "            \"QT_CONC_50_59\",\n",
    "            \"QT_CONC_60_MAIS\",\n",
    "            \"QT_CONC_BRANCA\",\n",
    "            \"QT_CONC_PRETA\",\n",
    "            \"QT_CONC_PARDA\",\n",
    "            \"QT_CONC_AMARELA\",\n",
    "            \"QT_CONC_INDIGENA\",\n",
    "            \"QT_CONC_CORND\",\n",
    "            \"QT_CONC_NACBRAS\",\n",
    "            \"QT_CONC_NACESTRANG\",\n",
    "            \"QT_CONC_DEFICIENTE\",\n",
    "            \"CO_CURSO\",\n",
    "            \"NU_ANO_CENSO\",\n",
    "        ]\n",
    "    ]\n",
    "    del df_curso\n",
    "    df[\"CO_CURSO\"] = df[\"CO_CURSO\"].astype(int)\n",
    "    df[\"NU_ANO_CENSO\"] = df[\"NU_ANO_CENSO\"].astype(int)\n",
    "    df.sort_values([\"CO_CURSO\", \"NU_ANO_CENSO\"], inplace=True, ignore_index=True)\n",
    "    colunas = df.columns.tolist()\n",
    "    colunas = [\n",
    "        col.lower() for col in colunas if col not in [\"CO_CURSO\", \"NU_ANO_CENSO\"]\n",
    "    ]\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            col: col.lower()\n",
    "            for col in df.columns\n",
    "            if col not in [\"CO_CURSO\", \"NU_ANO_CENSO\"]\n",
    "        }\n",
    "    )\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"CO_CURSO\": \"id_curso\",\n",
    "            \"NU_ANO_CENSO\": \"id_ano\",\n",
    "        }\n",
    "    )\n",
    "    df.drop_duplicates(subset=[\"id_curso\", \"id_ano\"], inplace=True)\n",
    "    insert_dados(conn, \"Concluinte_Ano\", df)\n",
    "    del df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
